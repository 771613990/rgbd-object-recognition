{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import copy\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import pcl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import tfrecord_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dirpath_in = '/media/daniel/monster-data/rgbd-dataset-raw'\n",
    "dataset_dirpath_out = 'dataset/rgbd-dataset-tfrecords'\n",
    "test_instance_ids_filepath = 'dataset/testinstance_ids.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_load_filepaths(dataset_path, use_depth=False, use_pcd=False):\n",
    "    \"\"\"\n",
    "    Create datatset with filepaths. You can use either depth or pcd files.\n",
    "    \"\"\"\n",
    "    if (use_depth and use_pcd) or (not use_depth and not use_pcd):\n",
    "        assert ValueError, 'which files do you want to use?'\n",
    "    \n",
    "    dataset = {}\n",
    "    classes = [f for f in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, f))]\n",
    "    classes.sort()\n",
    "    for cls in tqdm(classes):\n",
    "        dataset[cls] = {}\n",
    "        cls_path = os.path.join(dataset_path, cls)\n",
    "        instances = os.listdir(cls_path)\n",
    "        instances.sort(key=lambda x: int(x.split('_')[-1]))\n",
    "        for inst in instances:\n",
    "            inst_path = os.path.join(cls_path, inst)\n",
    "            dataset[cls][inst] = {'img' : [], 'pcd' : [], 'loc': []}\n",
    "            inst_files = os.listdir(inst_path)\n",
    "            # Number of files\n",
    "            pcd_filenames = [f for f in inst_files if '.pcd' in f]\n",
    "            img_filenames = [f for f in inst_files if '_crop.png' in f]\n",
    "            loc_filenames = [f for f in inst_files if '_loc.txt' in f]\n",
    "            dpt_filenames = [f for f in inst_files if '_depthcrop.png' in f]\n",
    "            # Get number of sequences\n",
    "            if use_depth:\n",
    "                key_filenames = dpt_filenames\n",
    "                key_filenames.sort(key=lambda x: int(x.split('_')[-3]))\n",
    "                seq_number = int(key_filenames[-1].split('_')[-3])\n",
    "            if use_pcd:\n",
    "                key_filenames = pcd_filenames\n",
    "                key_filenames.sort(key=lambda x: int(x.split('_')[2]))\n",
    "                seq_number = int(key_filenames[-1].split('_')[2])\n",
    "            # For every sequence\n",
    "            for seq in range(1, seq_number+1):\n",
    "                inst_seq_name = inst + '_' + str(seq) + '_'\n",
    "                inst_seq_key_filenames = [f for f in key_filenames if inst_seq_name in f]\n",
    "                if use_depth:\n",
    "                    inst_seq_key_filenames.sort(key=lambda x:int(x.split('_')[-2]))\n",
    "                if use_pcd:\n",
    "                    inst_seq_key_filenames.sort(key=lambda x:int(x.split('_')[-1].split('.')[0]))\n",
    "                inst_seq_key_filenames = inst_seq_key_filenames[0::5]\n",
    "                # For each file \n",
    "                for key_filename in inst_seq_key_filenames:\n",
    "                    if use_depth:\n",
    "                        basename = '_'.join(key_filename.split('_')[:-1])\n",
    "                    if use_pcd:  \n",
    "                        basename = key_filename.split('.')[0]\n",
    "                    img_filename = [f for f in img_filenames if basename + '_crop.png' in f]\n",
    "                    if len(img_filename) != 1:\n",
    "                        print('problem with class: {} instance: {} basename: {}'.format(\n",
    "                            cls, inst, basename))\n",
    "                    loc_filename = [f for f in loc_filenames if basename + '_loc.txt' in f]\n",
    "                    if len(loc_filename) != 1:\n",
    "                        print('problem with class: {} instance: {} basename: {}'.format(\n",
    "                            cls, inst, basename))\n",
    "                    img_filepath = os.path.join(inst_path, img_filename[0])\n",
    "                    loc_filepath = os.path.join(inst_path, loc_filename[0])\n",
    "                    key_filepath = os.path.join(inst_path, key_filename)\n",
    "                    # Remember\n",
    "                    dataset[cls][inst]['img'].append(img_filepath)\n",
    "                    dataset[cls][inst]['loc'].append(loc_filepath)\n",
    "                    dataset[cls][inst]['pcd'].append(key_filepath)\n",
    "    return dataset\n",
    "\n",
    "def load_cross_validation_split(test_instance_ids_filepath):\n",
    "    cross_test_split = []\n",
    "    with open(test_instance_ids_filepath, 'r') as file:\n",
    "        data = file.readlines()\n",
    "    trials = np.sum(['******' in line for line in data])\n",
    "    for trial in range(1, trials+1):\n",
    "        test_inst_trial = []\n",
    "        start_line_idx = [idx for idx, line in enumerate(data) if '****** trial ' + str(trial) in line][0]\n",
    "        end_line_idx = [idx for idx, line in enumerate(data) if '****** trial ' + str(trial +1) in line]\n",
    "        if len(end_line_idx) == 0:\n",
    "            end_line_idx = len(data)-1\n",
    "        else:\n",
    "            end_line_idx = end_line_idx[0]\n",
    "        for line_idx in range(start_line_idx+1, end_line_idx):\n",
    "            test_inst = data[line_idx].strip()\n",
    "            if len(test_inst):\n",
    "                test_inst_trial.append(test_inst)\n",
    "        cross_test_split.append(test_inst_trial)\n",
    "    return cross_test_split\n",
    "\n",
    "def cross_validation_split(dataset_paths, test_split):\n",
    "    dataset_train = copy.deepcopy(dataset_paths)\n",
    "    dataset_test = {}\n",
    "    for test_instance in test_split:\n",
    "        class_name = '_'.join(test_instance.split('_')[:-1])\n",
    "        if class_name not in dataset_test:\n",
    "            dataset_test[class_name] = {}\n",
    "        dataset_test[class_name][test_instance] = dataset_train[class_name].pop(test_instance)\n",
    "    return dataset_train, dataset_test\n",
    "\n",
    "def dataset_make_flat(dataset): \n",
    "    flat_dataset = copy.deepcopy(dataset)\n",
    "    for class_name in dataset:\n",
    "        flat_dataset[class_name] = {'img' : [], 'pcd': [], 'loc': []}\n",
    "        for key in ['img', 'pcd', 'loc']:\n",
    "            for instance_name in dataset[class_name]:\n",
    "                flat_dataset[class_name][key] = np.concatenate(\n",
    "                    (flat_dataset[class_name][key], dataset[class_name][instance_name][key]))\n",
    "    return flat_dataset\n",
    "\n",
    "def dataset_convert_to_x_and_y(dataset, class_names, shuffle=True):\n",
    "    X = {'img' : [], 'loc': []}\n",
    "    Y = {'name': [], 'int': []}\n",
    "    for class_idx, class_name in enumerate(class_names):\n",
    "        for key in ['img', 'loc']:\n",
    "            x_key = dataset[class_name][key]\n",
    "            X[key] = np.concatenate((X[key], x_key))\n",
    "        y_name = np.array([class_name]*len(x_key))\n",
    "        y_int = np.array([class_idx]*len(x_key))\n",
    "        Y['int'] = np.concatenate((Y['int'], y_int)).astype(int)\n",
    "        Y['name'] = np.concatenate((Y['name'], y_name))\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(Y['name']))\n",
    "        np.random.shuffle(indices)\n",
    "        for key in ['img', 'loc']:\n",
    "            X[key] = X[key][indices]\n",
    "        Y['int'] = Y['int'][indices]\n",
    "        Y['name'] = Y['name'][indices]\n",
    "    return X, Y\n",
    "\n",
    "def load_pcd(filepath):\n",
    "    pcd = pcl.load(filepath)\n",
    "    return np.asarray(pcd)\n",
    "\n",
    "def tfrecord_generate_point_cloud_data(X, Y, output_dir, split, pad_for='pointnet'):\n",
    "    global max_point_cloud_size\n",
    "    # tfrecords count\n",
    "    num_per_shard = 1500\n",
    "    num_shards = int(np.ceil(len(Y['name'])/num_per_shard))\n",
    "    \n",
    "    # Start TF session\n",
    "    with tf.Graph().as_default():\n",
    "        with tf.Session('') as _:\n",
    "            for shard_id in range(num_shards):\n",
    "                shard_filename = '%s_%s_%05d-of-%05d.tfrecord' % (split, 'rgbd', shard_id, num_shards)\n",
    "                shard_filepath = os.path.join(output_dir, shard_filename)\n",
    "                with tf.python_io.TFRecordWriter(shard_filepath) as tfrecord_writer:\n",
    "                    start_idx = shard_id * num_per_shard\n",
    "                    end_idx = min((shard_id + 1) * num_per_shard, len(Y['name']))\n",
    "                    for data_idx in tqdm(range(start_idx, end_idx)):\n",
    "                        # Load PCD/PNG\n",
    "                        x_cloud = load_pcd(X['pcd'][data_idx])\n",
    "                        y_int = Y['int'][data_idx]\n",
    "                        y_name = str(Y['name'][data_idx])\n",
    "                        if len(x_cloud) < max_point_cloud_size and pad_for=='pointnet':\n",
    "                            pad_size = max_point_cloud_size - len(x_cloud)\n",
    "                            x_cloud = np.pad(x_cloud, ((0, pad_size), (0, 0)), 'edge')\n",
    "                        tf_example = tfrecord_utils.point_cloud_to_tfexample(x_cloud, y_name, y_int)\n",
    "                        tfrecord_writer.write(tf_example.SerializeToString())\n",
    "                        \n",
    "def tfrecord_generate_paths(X, Y, output_dir, split):\n",
    "\n",
    "    # tfrecords count\n",
    "    num_per_shard = 10**5\n",
    "    num_shards = int(np.ceil(len(Y['name'])/num_per_shard))\n",
    "    \n",
    "    # Start TF session\n",
    "    with tf.Graph().as_default():\n",
    "        with tf.Session('') as _:\n",
    "            for shard_id in range(num_shards):\n",
    "                shard_filename = '%s_%s_%05d-of-%05d.tfrecord' % (split, 'rgbd', shard_id, num_shards)\n",
    "                shard_filepath = os.path.join(output_dir, shard_filename)\n",
    "                with tf.python_io.TFRecordWriter(shard_filepath) as tfrecord_writer:\n",
    "                    start_idx = shard_id * num_per_shard\n",
    "                    end_idx = min((shard_id + 1) * num_per_shard, len(Y['name']))\n",
    "                    for data_idx in tqdm(range(start_idx, end_idx)):\n",
    "                        x_img_path = X['img'][data_idx]\n",
    "                        x_pcd_path = X['pcd'][data_idx]\n",
    "                        x_loc_path = X['loc'][data_idx]\n",
    "                        y_int = Y['int'][data_idx]\n",
    "                        y_name = str(Y['name'][data_idx])\n",
    "                        tf_example = tfrecord_utils.paths_to_tfexample(x_pcd_path, x_img_path, x_loc_path, y_name, y_int)\n",
    "                        tfrecord_writer.write(tf_example.SerializeToString())\n",
    "                        \n",
    "def tfrecord_generate_depth_image_data(X, Y, output_dir, split):\n",
    "\n",
    "    # tfrecords count\n",
    "    num_per_shard = 2*10**3\n",
    "    num_shards = int(np.ceil(len(Y['name'])/num_per_shard))\n",
    "    \n",
    "    # Start TF session\n",
    "    with tf.Graph().as_default():\n",
    "        with tf.Session('') as _:\n",
    "            for shard_id in range(num_shards):\n",
    "                shard_filename = '%s_%s_%05d-of-%05d.tfrecord' % (split, 'rgbd', shard_id, num_shards)\n",
    "                shard_filepath = os.path.join(output_dir, shard_filename)\n",
    "                with tf.python_io.TFRecordWriter(shard_filepath) as tfrecord_writer:\n",
    "                    start_idx = shard_id * num_per_shard\n",
    "                    end_idx = min((shard_id + 1) * num_per_shard, len(Y['name']))\n",
    "                    for data_idx in tqdm(range(start_idx, end_idx)):\n",
    "                        # Load depth image\n",
    "                        x_img = cv2.imread(X['img'][data_idx], cv2.IMREAD_ANYDEPTH)\n",
    "                        # Load loc file\n",
    "                        with open(X['loc'][data_idx], 'r') as f:\n",
    "                            loc = np.array([int(l) for l in f.read().strip().split(',')])\n",
    "                        # Any problem?\n",
    "                        if x_img is None or loc is None:\n",
    "                            print('Problem with: {} or {}'.format(X['img'][data_idx], X['loc'][data_idx]))\n",
    "                            continue\n",
    "                        # Read Y\n",
    "                        y_int = Y['int'][data_idx]\n",
    "                        y_name = str(Y['name'][data_idx])\n",
    "                        # Serialize\n",
    "                        tf_example = tfrecord_utils.depth_image_to_tfexample(x_img.astype(np.float32), loc, y_name, y_int)\n",
    "                        tfrecord_writer.write(tf_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_depth_image=True\n",
    "use_pcd_files=False\n",
    "dataset_paths = dataset_load_filepaths(dataset_dirpath_in, use_depth_image, use_pcd_files)\n",
    "cross_test_split = load_cross_validation_split(test_instance_ids_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For each split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:08<00:00, 229.35it/s]\n",
      "100%|██████████| 2000/2000 [00:07<00:00, 253.76it/s]\n",
      " 62%|██████▏   | 1242/2000 [00:03<00:03, 250.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with: /media/daniel/monster-data/rgbd-dataset-raw/pitcher/pitcher_3/pitcher_3_2_91_crop.png or /media/daniel/monster-data/rgbd-dataset-raw/pitcher/pitcher_3/pitcher_3_2_91_loc.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:06<00:00, 318.49it/s]\n",
      "100%|██████████| 1041/1041 [00:02<00:00, 376.42it/s]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(dataset_dirpath_out):\n",
    "    os.makedirs(dataset_dirpath_out)\n",
    "    \n",
    "for split_idx, test_split in enumerate(cross_test_split[:1]):\n",
    "    \n",
    "    ################################################################\n",
    "    # Make dir\n",
    "    ################################################################\n",
    "    \n",
    "    split_dirpath = os.path.join(dataset_dirpath_out, str(split_idx+1))\n",
    "    if not os.path.exists(split_dirpath):\n",
    "        os.makedirs(split_dirpath)\n",
    "    \n",
    "    ################################################################\n",
    "    # Split dataset\n",
    "    ################################################################\n",
    "    \n",
    "    train_filepaths, test_filepaths = cross_validation_split(dataset_paths, test_split)\n",
    "    train_filepaths = dataset_make_flat(train_filepaths)\n",
    "    test_filepaths = dataset_make_flat(test_filepaths)\n",
    "    class_names = list(train_filepaths)\n",
    "    class_names.sort()\n",
    "    \n",
    "    ################################################################\n",
    "    # Prepare train data\n",
    "    ################################################################\n",
    "    \n",
    "    train_dirpath = os.path.join(split_dirpath, 'train')\n",
    "    if not os.path.exists(train_dirpath):\n",
    "        os.makedirs(train_dirpath)\n",
    "    \n",
    "#     X, Y = dataset_convert_to_x_and_y(train_filepaths, class_names, shuffle=True)\n",
    "#     #tfrecord_generate_paths(X, Y, train_dirpath, 'train')\n",
    "#     tfrecord_generate_depth_image_data(X, Y, train_dirpath, 'train')\n",
    "    \n",
    "    ################################################################\n",
    "    # Prepare test data\n",
    "    ################################################################\n",
    "    \n",
    "    test_dirpath = os.path.join(split_dirpath, 'test')\n",
    "    if not os.path.exists(test_dirpath):\n",
    "        os.makedirs(test_dirpath)\n",
    "        \n",
    "    X, Y = dataset_convert_to_x_and_y(test_filepaths, class_names, shuffle=False)\n",
    "    #tfrecord_generate_paths(X, Y, test_dirpath, 'test')\n",
    "    tfrecord_generate_depth_image_data(X, Y, test_dirpath, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert depth image to point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_filepath = '/media/daniel/monster-data/rgbd-dataset-raw/banana/banana_1/banana_1_1_1.pcd'\n",
    "depth_filepath = '/media/daniel/monster-data/rgbd-dataset-raw/banana/banana_1/banana_1_1_1_depthcrop.png'\n",
    "image_filepath = '/media/daniel/monster-data/rgbd-dataset-raw/banana/banana_1/banana_1_1_1_crop.png'\n",
    "crop_top_left_corner = [227, 245]\n",
    "\n",
    "color = cv2.imread(image_filepath)\n",
    "depth = cv2.imread(depth_filepath, cv2.IMREAD_ANYDEPTH)#.astype(np.float32)\n",
    "plt.imshow(depth)\n",
    "plt.show()\n",
    "\n",
    "print(depth.shape, depth.dtype, depth[0][0])\n",
    "print(np.max(depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depth conversion\n",
    "depth = depth.astype(np.float32)\n",
    "depth[depth == 0] = np.nan\n",
    "print(depth.shape, depth.dtype, depth[0][0])\n",
    "print(np.max(depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_point_cloud(depth_image, crop_top_left_corner=None, color_image=None):\n",
    "    # Depth conversion\n",
    "    depth = depth_image.astype(np.float32)\n",
    "    depth[depth == 0] = np.nan\n",
    "    # RGB-D camera constants\n",
    "    center = [320, 240]\n",
    "    image_h, image_w = depth.shape\n",
    "    scale_f = 570.3\n",
    "    mm_per_m = 1000\n",
    "    if crop_top_left_corner is None:\n",
    "        crop_top_left_corner = [0, 0]\n",
    "    # Convert depth image to 3d point cloud\n",
    "    channels = 3\n",
    "    if color_image is not None:\n",
    "        channels = 6\n",
    "    point_cloud = np.zeros((image_h, image_w, channels), dtype=np.float32)\n",
    "    x_grid = np.ones((image_h, 1), dtype=np.float32) * np.arange(image_w) + crop_top_left_corner[0] - center[0]\n",
    "    y_grid = (np.arange(image_h).reshape(image_h, 1)*np.ones((1, image_w), dtype=np.float32) +\n",
    "              crop_top_left_corner[1] - center[1])\n",
    "    point_cloud[..., 0] = np.multiply(x_grid, depth) / scale_f / mm_per_m\n",
    "    point_cloud[..., 1] = np.multiply(y_grid, depth) / scale_f / mm_per_m\n",
    "    point_cloud[..., 2] = depth / mm_per_m\n",
    "    # Assign color to point cloud\n",
    "    if color_image is not None:\n",
    "        point_cloud[..., 3:] = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB).astype(np.float32) / 255\n",
    "    # Cut off to far points\n",
    "    point_cloud[point_cloud[..., 2] > 2.5] = np.nan\n",
    "    return point_cloud\n",
    "\n",
    "\n",
    "def build_point_cloud_from_depth_image(depth_image, depth_intrinsic, depth_multiplier=0.001,\n",
    "                                       crop_top_left_corner=None, full_image_size=[640, 480]):\n",
    "    \"\"\"\n",
    "    Convert depth image to organized point cloud using intrinsic calibraion of the camera.\n",
    "\n",
    "    Args:\n",
    "        depth_image (np.array of shape NxM): Depth image.\n",
    "        depth_intrinsic (np.array): Intrisic matrtix of a depth camera.\n",
    "\n",
    "    Returns:\n",
    "        (np.array NxMx3): Organized point cloud.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Build full image\n",
    "    full_image = np.zeros(shape=full_image_size[::-1], dtype=np.float32)\n",
    "    \n",
    "    # Insert depth crop inside the image\n",
    "    if crop_top_left_corner is None:\n",
    "        crop_top_left_corner = [0, 0]\n",
    "    full_image[crop_top_left_corner[1]:crop_top_left_corner[1]+depth_image.shape[0],\n",
    "               crop_top_left_corner[0]:crop_top_left_corner[0]+depth_image.shape[1]] = depth_image\n",
    "    \n",
    "    # Convert to point cloud\n",
    "    organized_point_cloud = cv2.rgbd.depthTo3d(full_image, depth_intrinsic)\n",
    "    \n",
    "    # Crop point cloud to original size\n",
    "    organized_point_cloud = organized_point_cloud[crop_top_left_corner[1]:crop_top_left_corner[1]+depth_image.shape[0],\n",
    "                                                  crop_top_left_corner[0]:crop_top_left_corner[0]+depth_image.shape[1]]\n",
    "    return organized_point_cloud * depth_multiplier\n",
    "\n",
    "depth_intrinsic = np.zeros(shape=(3, 3))\n",
    "depth_intrinsic[0, 0] = 570.3\n",
    "depth_intrinsic[1, 1] = 570.3\n",
    "depth_intrinsic[0, 2] = 320\n",
    "depth_intrinsic[1, 2] = 240\n",
    "depth_intrinsic[2, 2] = 1.\n",
    "depth_multiplier = 0.001\n",
    "\n",
    "# Old way\n",
    "point_cloud = create_point_cloud(depth, crop_top_left_corner)\n",
    "point_cloud_2 = build_point_cloud_from_depth_image(depth_image=depth, depth_intrinsic=depth_intrinsic,\n",
    "                                                   depth_multiplier=depth_multiplier,\n",
    "                                                   crop_top_left_corner=crop_top_left_corner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
