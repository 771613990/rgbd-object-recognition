{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "#from pypcd.pypcd import make_xyz_rgb_point_cloud\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import pcl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import tfrecord_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dirpath_in = '/media/daniel/monster-data/rgbd-dataset-raw'\n",
    "dataset_dirpath_out = '/media/daniel/monster-data/rgbd-dataset-tfrecords'\n",
    "test_instance_ids_filepath = 'dataset/testinstance_ids.txt'\n",
    "max_point_cloud_size = 44214"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_load_filepaths(dataset_path, use_depth=False, use_pcd=False):\n",
    "    \"\"\"\n",
    "    Create datatset with filepaths. You can use either depth or pcd files.\n",
    "    \"\"\"\n",
    "    if (use_depth and use_pcd) or (not use_depth and not use_pcd):\n",
    "        assert ValueError, 'which files do you want to use?'\n",
    "    \n",
    "    dataset = {}\n",
    "    classes = [f for f in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, f))]\n",
    "    classes.sort()\n",
    "    for cls in tqdm(classes):\n",
    "        dataset[cls] = {}\n",
    "        cls_path = os.path.join(dataset_path, cls)\n",
    "        instances = os.listdir(cls_path)\n",
    "        instances.sort(key=lambda x: int(x.split('_')[-1]))\n",
    "        for inst in instances:\n",
    "            inst_path = os.path.join(cls_path, inst)\n",
    "            dataset[cls][inst] = {'img' : [], 'pcd' : [], 'loc': []}\n",
    "            inst_files = os.listdir(inst_path)\n",
    "            # Number of files\n",
    "            pcd_filenames = [f for f in inst_files if '.pcd' in f]\n",
    "            img_filenames = [f for f in inst_files if '_crop.png' in f]\n",
    "            loc_filenames = [f for f in inst_files if '_loc.txt' in f]\n",
    "            dpt_filenames = [f for f in inst_files if '_depthcrop.png' in f]\n",
    "            # Get number of sequences\n",
    "            if use_depth:\n",
    "                key_filenames = dpt_filenames\n",
    "                key_filenames.sort(key=lambda x: int(x.split('_')[-3]))\n",
    "                seq_number = int(key_filenames[-1].split('_')[-3])\n",
    "            if use_pcd:\n",
    "                key_filenames = pcd_filenames\n",
    "                key_filenames.sort(key=lambda x: int(x.split('_')[2]))\n",
    "                seq_number = int(key_filenames[-1].split('_')[2])\n",
    "            # For every sequence\n",
    "            for seq in range(1, seq_number+1):\n",
    "                inst_seq_name = inst + '_' + str(seq) + '_'\n",
    "                inst_seq_key_filenames = [f for f in key_filenames if inst_seq_name in f]\n",
    "                if use_depth:\n",
    "                    inst_seq_key_filenames.sort(key=lambda x:int(x.split('_')[-2]))\n",
    "                if use_pcd:\n",
    "                    inst_seq_key_filenames.sort(key=lambda x:int(x.split('_')[-1].split('.')[0]))\n",
    "                inst_seq_key_filenames = inst_seq_key_filenames[0::5]\n",
    "                # For each file \n",
    "                for key_filename in inst_seq_key_filenames:\n",
    "                    if use_depth:\n",
    "                        basename = '_'.join(key_filename.split('_')[:-1])\n",
    "                    if use_pcd:  \n",
    "                        basename = key_filename.split('.')[0]\n",
    "                    img_filename = [f for f in img_filenames if basename + '_crop.png' in f]\n",
    "                    if len(img_filename) != 1:\n",
    "                        print('problem with class: {} instance: {} basename: {}'.format(\n",
    "                            cls, inst, basename))\n",
    "                    loc_filename = [f for f in loc_filenames if basename + '_loc.txt' in f]\n",
    "                    if len(loc_filename) != 1:\n",
    "                        print('problem with class: {} instance: {} basename: {}'.format(\n",
    "                            cls, inst, basename))\n",
    "                    img_filepath = os.path.join(inst_path, img_filename[0])\n",
    "                    loc_filepath = os.path.join(inst_path, loc_filename[0])\n",
    "                    key_filepath = os.path.join(inst_path, key_filename)\n",
    "                    # Remember\n",
    "                    dataset[cls][inst]['img'].append(img_filepath)\n",
    "                    dataset[cls][inst]['loc'].append(loc_filepath)\n",
    "                    dataset[cls][inst]['pcd'].append(key_filepath)\n",
    "    return dataset\n",
    "\n",
    "def load_cross_validation_split(test_instance_ids_filepath):\n",
    "    cross_test_split = []\n",
    "    with open(test_instance_ids_filepath, 'r') as file:\n",
    "        data = file.readlines()\n",
    "    trials = np.sum(['******' in line for line in data])\n",
    "    for trial in range(1, trials+1):\n",
    "        test_inst_trial = []\n",
    "        start_line_idx = [idx for idx, line in enumerate(data) if '****** trial ' + str(trial) in line][0]\n",
    "        end_line_idx = [idx for idx, line in enumerate(data) if '****** trial ' + str(trial +1) in line]\n",
    "        if len(end_line_idx) == 0:\n",
    "            end_line_idx = len(data)-1\n",
    "        else:\n",
    "            end_line_idx = end_line_idx[0]\n",
    "        for line_idx in range(start_line_idx+1, end_line_idx):\n",
    "            test_inst = data[line_idx].strip()\n",
    "            if len(test_inst):\n",
    "                test_inst_trial.append(test_inst)\n",
    "        cross_test_split.append(test_inst_trial)\n",
    "    return cross_test_split\n",
    "\n",
    "def cross_validation_split(dataset_paths, test_split):\n",
    "    dataset_train = copy.deepcopy(dataset_paths)\n",
    "    dataset_test = {}\n",
    "    for test_instance in test_split:\n",
    "        class_name = '_'.join(test_instance.split('_')[:-1])\n",
    "        if class_name not in dataset_test:\n",
    "            dataset_test[class_name] = {}\n",
    "        dataset_test[class_name][test_instance] = dataset_train[class_name].pop(test_instance)\n",
    "    return dataset_train, dataset_test\n",
    "\n",
    "def dataset_make_flat(dataset): \n",
    "    flat_dataset = copy.deepcopy(dataset)\n",
    "    for class_name in dataset:\n",
    "        flat_dataset[class_name] = {'img' : [], 'pcd': [], 'loc': []}\n",
    "        for key in ['img', 'pcd', 'loc']:\n",
    "            for instance_name in dataset[class_name]:\n",
    "                flat_dataset[class_name][key] = np.concatenate(\n",
    "                    (flat_dataset[class_name][key], dataset[class_name][instance_name][key]))\n",
    "    return flat_dataset\n",
    "\n",
    "def dataset_convert_to_x_and_y(dataset, class_names, shuffle=True):\n",
    "    X = {'img' : [], 'pcd': [], 'loc': []}\n",
    "    Y = {'name': [], 'int': []}\n",
    "    for class_idx, class_name in enumerate(class_names):\n",
    "        for key in ['img', 'pcd', 'loc']:\n",
    "            x_key = dataset[class_name][key]\n",
    "            X[key] = np.concatenate((X[key], x_key))\n",
    "        y_name = np.array([class_name]*len(x_key))\n",
    "        y_int = np.array([class_idx]*len(x_key))\n",
    "        Y['int'] = np.concatenate((Y['int'], y_int)).astype(int)\n",
    "        Y['name'] = np.concatenate((Y['name'], y_name))\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(Y['name']))\n",
    "        np.random.shuffle(indices)\n",
    "        for key in ['img', 'pcd', 'loc']:\n",
    "            X[key] = X[key][indices]\n",
    "        Y['int'] = Y['int'][indices]\n",
    "        Y['name'] = Y['name'][indices]\n",
    "    return X, Y\n",
    "\n",
    "def load_pcd(filepath):\n",
    "    pcd = pcl.load(filepath)\n",
    "    return np.asarray(pcd)\n",
    "\n",
    "def tfrecord_generate_data(X, Y, output_dir, split, pad_for='pointnet'):\n",
    "    global max_point_cloud_size\n",
    "    # tfrecords count\n",
    "    num_per_shard = 1500\n",
    "    num_shards = int(np.ceil(len(Y['name'])/num_per_shard))\n",
    "    \n",
    "    # Start TF session\n",
    "    with tf.Graph().as_default():\n",
    "        with tf.Session('') as _:\n",
    "            for shard_id in range(num_shards):\n",
    "                shard_filename = '%s_%s_%05d-of-%05d.tfrecord' % (split, 'rgbd', shard_id, num_shards)\n",
    "                shard_filepath = os.path.join(output_dir, shard_filename)\n",
    "                with tf.python_io.TFRecordWriter(shard_filepath) as tfrecord_writer:\n",
    "                    start_idx = shard_id * num_per_shard\n",
    "                    end_idx = min((shard_id + 1) * num_per_shard, len(Y['name']))\n",
    "                    for data_idx in tqdm(range(start_idx, end_idx)):\n",
    "                        # Load PCD/PNG\n",
    "                        x_cloud = load_pcd(X['pcd'][data_idx])\n",
    "                        y_int = Y['int'][data_idx]\n",
    "                        y_name = str(Y['name'][data_idx])\n",
    "                        if len(x_cloud) < max_point_cloud_size and pad_for=='pointnet':\n",
    "                            pad_size = max_point_cloud_size - len(x_cloud)\n",
    "                            x_cloud = np.pad(x_cloud, ((0, pad_size), (0, 0)), 'edge')\n",
    "                        tf_example = tfrecord_utils.point_cloud_to_tfexample(x_cloud, y_name, y_int)\n",
    "                        tfrecord_writer.write(tf_example.SerializeToString())\n",
    "                        \n",
    "def tfrecord_generate_paths(X, Y, output_dir, split,):\n",
    "\n",
    "    # tfrecords count\n",
    "    num_per_shard = 10**5\n",
    "    num_shards = int(np.ceil(len(Y['name'])/num_per_shard))\n",
    "    \n",
    "    # Start TF session\n",
    "    with tf.Graph().as_default():\n",
    "        with tf.Session('') as _:\n",
    "            for shard_id in range(num_shards):\n",
    "                shard_filename = '%s_%s_%05d-of-%05d.tfrecord' % (split, 'rgbd', shard_id, num_shards)\n",
    "                shard_filepath = os.path.join(output_dir, shard_filename)\n",
    "                with tf.python_io.TFRecordWriter(shard_filepath) as tfrecord_writer:\n",
    "                    start_idx = shard_id * num_per_shard\n",
    "                    end_idx = min((shard_id + 1) * num_per_shard, len(Y['name']))\n",
    "                    for data_idx in tqdm(range(start_idx, end_idx)):\n",
    "                        x_img_path = X['img'][data_idx]\n",
    "                        x_pcd_path = X['pcd'][data_idx]\n",
    "                        x_loc_path = X['loc'][data_idx]\n",
    "                        y_int = Y['int'][data_idx]\n",
    "                        y_name = str(Y['name'][data_idx])\n",
    "                        tf_example = tfrecord_utils.paths_to_tfexample(x_pcd_path, x_img_path, x_loc_path, y_name, y_int)\n",
    "                        tfrecord_writer.write(tf_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:17<00:00,  2.84it/s]\n"
     ]
    }
   ],
   "source": [
    "use_depth_image=True\n",
    "use_pcd_files=False\n",
    "dataset_paths = dataset_load_filepaths(dataset_dirpath_in, use_depth_image, use_pcd_files)\n",
    "cross_test_split = load_cross_validation_split(test_instance_ids_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For each split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34898/34898 [23:27<00:00, 24.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth: (457510099,)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'asdasd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7edc782ec92e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mdepths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'depth:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0masdasd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mtfrecord_generate_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dirpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'asdasd' is not defined"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(dataset_dirpath_out):\n",
    "    os.makedirs(dataset_dirpath_out)\n",
    "    \n",
    "for split_idx, test_split in enumerate(cross_test_split[:1]):\n",
    "    ################################################################\n",
    "    # Make dir\n",
    "    ################################################################\n",
    "    \n",
    "    split_dirpath = os.path.join(dataset_dirpath_out, str(split_idx+1))\n",
    "    if not os.path.exists(split_dirpath):\n",
    "        os.makedirs(split_dirpath)\n",
    "    \n",
    "    ################################################################\n",
    "    # Split dataset\n",
    "    ################################################################\n",
    "    \n",
    "    train_filepaths, test_filepaths = cross_validation_split(dataset_paths, test_split)\n",
    "    train_filepaths = dataset_make_flat(train_filepaths)\n",
    "    test_filepaths = dataset_make_flat(test_filepaths)\n",
    "    class_names = list(train_filepaths)\n",
    "    class_names.sort()\n",
    "    \n",
    "    ################################################################\n",
    "    # Prepare train data\n",
    "    ################################################################\n",
    "    \n",
    "    train_dirpath = os.path.join(split_dirpath, 'train')\n",
    "    if not os.path.exists(train_dirpath):\n",
    "        os.makedirs(train_dirpath)\n",
    "    \n",
    "    depth_min = np.inf\n",
    "    depth_max = -np.inf\n",
    "    depths = []\n",
    "    \n",
    "    X, Y = dataset_convert_to_x_and_y(train_filepaths, class_names, shuffle=True)\n",
    "    for depth_filepath in tqdm(X['pcd']):\n",
    "        depth = cv2.imread(depth_filepath, cv2.IMREAD_ANYDEPTH)\n",
    "        depth = depth.astype(np.float32)\n",
    "        depths.append(depth.reshape(-1))\n",
    "#         if depth_min > np.min(depth):\n",
    "#             depth_min = np.min(depth)\n",
    "#         if depth_max < np.max(depth):\n",
    "#             depth_max = np.max(depth)\n",
    "\n",
    "    depths = np.concatenate(depths)\n",
    "    print('depth:', depths.shape)\n",
    "    asdasd\n",
    "    tfrecord_generate_paths(X, Y, train_dirpath, 'train')\n",
    "    \n",
    "    ################################################################\n",
    "    # Prepare test data\n",
    "    ################################################################\n",
    "    \n",
    "    test_dirpath = os.path.join(split_dirpath, 'test')\n",
    "    if not os.path.exists(test_dirpath):\n",
    "        os.makedirs(test_dirpath)\n",
    "        \n",
    "    X, Y = dataset_convert_to_x_and_y(test_filepaths, class_names, shuffle=False)\n",
    "    tfrecord_generate_paths(X, Y, test_dirpath, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(775.6092, 499.1676)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(depths), np.std(depths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert depth image to point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_filepath = '/media/daniel/Atos/rgbd-dataset/banana/banana_1/banana_1_1_1.pcd'\n",
    "depth_filepath = '/media/daniel/Atos/rgbd-dataset/banana/banana_1/banana_1_1_1_depthcrop.png'\n",
    "image_filepath = '/media/daniel/Atos/rgbd-dataset/banana/banana_1/banana_1_1_1_crop.png'\n",
    "crop_top_left_corner = [227, 245]\n",
    "\n",
    "color = cv2.imread(image_filepath)\n",
    "depth = cv2.imread(depth_filepath, cv2.IMREAD_ANYDEPTH)\n",
    "plt.imshow(depth)\n",
    "plt.show()\n",
    "\n",
    "print(depth.shape, depth.dtype, depth[0][0])\n",
    "print(np.max(depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depth conversion\n",
    "depth = depth.astype(np.float32)\n",
    "depth[depth == 0] = np.nan\n",
    "print(depth.shape, depth.dtype, depth[0][0])\n",
    "print(np.max(depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_point_cloud(depth_image, crop_top_left_corner=None, color_image=None):\n",
    "    # Depth conversion\n",
    "    depth = depth_image.astype(np.float32)\n",
    "    depth[depth == 0] = np.nan\n",
    "    # RGB-D camera constants\n",
    "    center = [320, 240]\n",
    "    image_h, image_w = depth.shape\n",
    "    scale_f = 570.3\n",
    "    mm_per_m = 1000\n",
    "    if crop_top_left_corner is None:\n",
    "        crop_top_left_corner = [0, 0]\n",
    "    # Convert depth image to 3d point cloud\n",
    "    channels = 3\n",
    "    if color_image is not None:\n",
    "        channels = 6\n",
    "    point_cloud = np.zeros((image_h, image_w, channels), dtype=np.float32)\n",
    "    x_grid = np.ones((image_h, 1), dtype=np.float32) * np.arange(image_w) + crop_top_left_corner[0] - center[0]\n",
    "    y_grid = (np.arange(image_h).reshape(image_h, 1)*np.ones((1, image_w), dtype=np.float32) +\n",
    "              crop_top_left_corner[1] - center[1])\n",
    "    point_cloud[..., 0] = np.multiply(x_grid, depth) / scale_f / mm_per_m\n",
    "    point_cloud[..., 1] = np.multiply(y_grid, depth) / scale_f / mm_per_m\n",
    "    point_cloud[..., 2] = depth / mm_per_m\n",
    "    # Assign color to point cloud\n",
    "    if color_image is not None:\n",
    "        point_cloud[..., 3:] = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB).astype(np.float32) / 255\n",
    "    # Cut off to far points\n",
    "    point_cloud[point_cloud[..., 2] > 2.5] = np.nan\n",
    "    return point_cloud\n",
    "\n",
    "\n",
    "point_cloud = create_point_cloud(depth, crop_top_left_corner)\n",
    "temp = pcl.PointCloud(point_cloud.reshape(-1, 3))\n",
    "pcl.save(temp, '/home/daniel/temp.pcd')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
